# GDSC 3주차 과제

## 2. Loss의 종류

 Loss의 종류에 대하여 알아보기 전에 Loss가 어떤 역할을 하는지부터 알아보도록 합시다.

### Loss Function이란 무엇일까?

 Loss는 말 그대로 해석하자면 오차라는 뜻을 가지고 있습니다. 이를 딥러닝 모델에 대입시켜보면 모델의 출력값과 의도하는 출력값의 오차를 의미하는 것입니다. 

그렇기에 모델을 만들고자 할 때, 우리는 손실함수의 함수값이 최소화되도록 가중치(weight)와 편향(bias)을 조정해주는 과정을 겪게 됩니다.



### Loss Function의 종류

딥러닝에서 사용하는 Loss Function은 정말 많은 종류가 있습니다. 아래 사진은 [Pytorch 공식문서](https://pytorch.org/docs/stable/nn.html#loss-functions)에서 `torch.nn`으로서 공식적으로 지원하는 Loss Function을 나열한 사진입니다. 물론 이 그림에서 다 나열된 것은 아니지만 공식문서에서의 Loss의 개수만 무려 21개가 넘습니다. 😱

 <div align = "center"> <img src="https://drive.google.com/uc?id=1Z9YY_Znmiu8YGqD2skKz0u5lrWfJ72mV"> </div>

이렇게 많은 Loss 함수 중에서 가장 잘 알려진 `crossentropy` 와 `MSE` 에 대하여 중점적으로 알아보도록 하겠습니다.

#### 1. Cross Entropy Loss

우선, Cross Entropy에는 binary-class-classification을 훈련할 때 주로 사용되는 `binary_crossentropy`와 분류해야하는 클래스가 2개 이상일 경우인 multi-class-classification에 대하여 주로 사용되는 `categorical_crossentropy`가 있습니다.

먼저, `binary_crossentropy` 에 대하여 알아보도록 합시다.

 `binary_crossentropy` 와 관련된 [pytorch 공식문서]("https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html#torch.nn.BCELoss")를 살펴보자면  `torch.nn.BCELoss()` 의 형태로 지원하는 것을 알 수 있습니다. 

<div align = "center"><img src=https://drive.google.com/uc?id=1RhwXRcqxkOXz4Wc-nXpBWEf6C_H386u4></div>





다음으로 `categorical_crossentropy` 에 대하여 알아보도록 합시다.

 `categorical_crossentropy` 와 관련된 [pytorch 공식문서]("https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss")를 살펴보자면 `torch.nn.CrossEntropyLoss()`의 형태로 지원하는 것을 알 수 있습니다.

<div align = "center"><img src="https://drive.google.com/uc?id=1Z_QjphsOYUKfvWUebpWA6g5okdFQTVm2"></div>



#### 2. MSE Loss

 `MSELoss` 에 대하여 알아보도록 합시다.

 `MSELoss` 와 관련된 [pytorch 공식문서]("https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss")를 살펴보자면 `torch.nn.MSELoss()`의 형태로 지원하는 것을 알 수 있습니다.

<div align = "center"><img src = "https://drive.google.com/uc?id=1Z8qwUAB0JGSkOz7wvfyQ2KhcWkBOqnHc"></div>







